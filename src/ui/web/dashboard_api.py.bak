"""
Dashboard API endpoints for report data feeds.

Exposes REST endpoints to feed real-time and historical metrics to the dashboard.
Includes caching for performance.
"""

import logging
import math
from typing import Dict, List, Optional, Tuple
from functools import lru_cache
from datetime import datetime, timedelta

from flask import Blueprint, jsonify, request

from src.reports.report_generator import ReportGenerator
from src.database.db_manager import DatabaseManager


logger = logging.getLogger(__name__)
cache = None  # Global cache instance


def clean_metrics(metrics_dict: dict) -> dict:
    """Clean all metrics to ensure they're JSON-serializable.

    Converts NaN and Infinity to 0, and ensures all values are valid JSON.

    Args:
        metrics_dict: Dictionary of metrics from backtest results

    Returns:
        Cleaned dictionary with valid JSON values
    """
    if not metrics_dict:
        return {}

    cleaned = {}
    for key, value in metrics_dict.items():
        if value is None:
            cleaned[key] = 0
        elif isinstance(value, float):
            if math.isnan(value) or math.isinf(value):
                cleaned[key] = 0
            else:
                cleaned[key] = value
        else:
            try:
                # Try to convert to float and check again
                float_val = float(value)
                if math.isnan(float_val) or math.isinf(float_val):
                    cleaned[key] = 0
                else:
                    cleaned[key] = value
            except (TypeError, ValueError):
                # Not numeric, keep as-is
                cleaned[key] = value

    return cleaned


def clean_response(obj):
    """Recursively clean any object to remove NaN/Infinity values.

    Args:
        obj: Any object (dict, list, or scalar value)

    Returns:
        Cleaned object with NaN/Infinity converted to 0
    """
    if isinstance(obj, dict):
        return {key: clean_response(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [clean_response(item) for item in obj]
    elif isinstance(obj, float):
        if math.isnan(obj) or math.isinf(obj):
            return 0
        return obj
    else:
        return obj


def init_cache():
    """Initialize cache for API."""
    global cache
    cache = ReportCache(ttl_seconds=300)


class DashboardAPI:
    """REST API for dashboard data feeds."""

    def __init__(self, db: DatabaseManager, config: Dict):
        """
        Initialize dashboard API.

        Args:
            db: DatabaseManager instance
            config: Configuration dict
        """
        self.db = db
        self.config = config
        self.report_gen = ReportGenerator(db, config)
        self.blueprint = self._create_blueprint()

    def _create_blueprint(self) -> Blueprint:
        """Create Flask blueprint with all API routes."""
        bp = Blueprint("api", __name__, url_prefix="/api")

        def get_db_connection():
            """Get a thread-safe database connection for this request."""
            db = DatabaseManager(self.config)
            db.connect()
            return db

        @bp.route("/comparison/strategies/<int:timeframe>", methods=["GET"])
        def get_strategy_comparison(timeframe):
            """Get comprehensive strategy comparison for a timeframe.

            Compares all strategies across all symbols with:
            - Best overall strategy (highest Sharpe ratio)
            - Profitable strategies (positive return)
            - Average metrics per strategy
            """
            cache_key = f"strategy_comparison_{timeframe}"
            if cache and cache.get(cache_key):
                return jsonify(cache.get(cache_key))

            db = None
            try:
                db = get_db_connection()
                cursor = db.conn.cursor()

                # Query strategy performance metrics - get raw metrics JSON for parsing in Python
                query = """
                    SELECT 
                        bs.name as strategy,
                        COUNT(*) as tested_pairs,
                        GROUP_CONCAT(b.metrics, '|') as all_metrics
                    FROM backtest_backtests b
                    JOIN backtest_strategies bs ON b.strategy_id = bs.id
                    WHERE b.timeframe = ? AND b.metrics IS NOT NULL
                    GROUP BY bs.name
                """

                tf_str = f"M{timeframe}" if timeframe < 60 else f"H{timeframe//60}"
                logger.debug(
                    f"Executing strategy comparison query for timeframe: {tf_str}"
                )
                cursor.execute(query, (tf_str,))
                results = cursor.fetchall()

                strategies = []
                for row in results:
                    strategy_name = row[0]
                    tested_pairs = row[1]
                    metrics_json_str = row[2]

                    # Parse metrics JSON strings
                    import json

                    metrics_list = []
                    if metrics_json_str:
                        for metrics_str in metrics_json_str.split("|"):
                            try:
                                metrics = json.loads(metrics_str)
                                # Clean metrics to remove NaN/Infinity
                                metrics = clean_metrics(metrics)
                                metrics_list.append(metrics)
                            except json.JSONDecodeError:
                                logger.warning(
                                    f"Failed to parse metrics JSON: {metrics_str}"
                                )
                                continue

                    if not metrics_list:
                        continue

                    # Calculate averages and statistics
                    avg_sharpe = sum(
                        m.get("sharpe_ratio", 0) for m in metrics_list
                    ) / len(metrics_list)
                    avg_return = sum(m.get("return", 0) for m in metrics_list) / len(
                        metrics_list
                    )
                    avg_profit_factor = sum(
                        m.get("profit_factor", 0) for m in metrics_list
                    ) / len(metrics_list)
                    profitable_pairs = sum(
                        1 for m in metrics_list if m.get("return", 0) > 0
                    )
                    avg_max_dd = sum(
                        m.get("max_drawdown", 0) for m in metrics_list
                    ) / len(metrics_list)
                    best_sharpe = max(m.get("sharpe_ratio", 0) for m in metrics_list)

                    strategies.append(
                        {
                            "name": strategy_name,
                            "tested_pairs": tested_pairs,
                            "avg_sharpe_ratio": round(avg_sharpe, 3),
                            "avg_return_pct": round(avg_return, 2),
                            "avg_profit_factor": round(avg_profit_factor, 2),
                            "profitable_pairs": profitable_pairs,
                            "win_rate": round(
                                (
                                    (profitable_pairs / tested_pairs * 100)
                                    if tested_pairs > 0
                                    else 0
                                ),
                                1,
                            ),
                            "avg_max_drawdown_pct": round(abs(avg_max_dd), 2),
                            "best_sharpe_ratio": round(best_sharpe, 3),
                        }
                    )

                # Sort by avg_sharpe_ratio
                strategies.sort(key=lambda x: x["avg_sharpe_ratio"], reverse=True)

                response = {
                    "status": "success",
                    "timeframe": timeframe,
                    "count": len(strategies),
                    "best_overall": strategies[0] if strategies else None,
                    "all_strategies": strategies,
                }

                # Clean response to remove NaN/Infinity values
                response = clean_response(response)

                if cache:
                    cache.set(cache_key, response)

                return jsonify(response)

            except Exception as e:
                logger.error(
                    f"Error in get_strategy_comparison (timeframe={timeframe}): {type(e).__name__}: {e}"
                )
                import traceback

                logger.error(f"Traceback: {traceback.format_exc()}")
                return jsonify({"error": str(e), "type": type(e).__name__}), 500
            finally:
                if db:
                    db.close()

        @bp.route("/comparison/pairs/<int:timeframe>", methods=["GET"])
        def get_pair_comparison(timeframe):
            """Get performance comparison across all trading pairs.

            Returns pairs ranked by Sharpe ratio with best strategy per pair.
            """
            strategy = request.args.get("strategy", None)  # Optional filter
            cache_key = f"pair_comparison_{timeframe}_{strategy}"
            if cache and cache.get(cache_key):
                return jsonify(cache.get(cache_key))

            db = None
            try:
                import json

                db = get_db_connection()
                cursor = db.conn.cursor()

                tf_str = f"M{timeframe}" if timeframe < 60 else f"H{timeframe//60}"
                logger.debug(f"Executing pair comparison query for timeframe: {tf_str}")

                # Get all pair data with raw metrics JSON for parsing in Python
                query = """
                    SELECT 
                        tp.symbol,
                        bs.name as strategy,
                        b.metrics
                    FROM backtest_backtests b
                    JOIN backtest_strategies bs ON b.strategy_id = bs.id
                    JOIN tradable_pairs tp ON b.symbol_id = tp.id
                    WHERE b.timeframe = ? AND b.metrics IS NOT NULL
                    ORDER BY tp.symbol, bs.name
                """

                cursor.execute(query, (tf_str,))
                results = cursor.fetchall()

                # Process results and find best per pair
                pair_data = {}
                for row in results:
                    symbol = row[0]
                    strategy_name = row[1]
                    metrics_json = row[2]

                    if symbol not in pair_data:
                        pair_data[symbol] = []

                    try:
                        metrics = json.loads(metrics_json)
                        # Clean metrics to remove NaN/Infinity
                        metrics = clean_metrics(metrics)
                        pair_data[symbol].append(
                            {"strategy": strategy_name, "metrics": metrics}
                        )
                    except json.JSONDecodeError:
                        logger.warning(f"Failed to parse metrics JSON for {symbol}")
                        continue

                # Find best per pair
                pairs = []
                for symbol in sorted(pair_data.keys()):
                    pair_metrics = pair_data[symbol]
                    if not pair_metrics:
                        continue

                    # Find best by sharpe ratio
                    best = max(
                        pair_metrics, key=lambda x: x["metrics"].get("sharpe_ratio", 0)
                    )

                    pairs.append(
                        {
                            "symbol": symbol,
                            "best_strategy": best["strategy"],
                            "sharpe_ratio": round(
                                best["metrics"].get("sharpe_ratio", 0), 3
                            ),
                            "return_pct": round(best["metrics"].get("return", 0), 2),
                            "profit_factor": round(
                                best["metrics"].get("profit_factor", 0), 2
                            ),
                            "max_drawdown_pct": round(
                                abs(best["metrics"].get("max_drawdown", 0)), 2
                            ),
                            "strategies_tested": len(pair_metrics),
                        }
                    )

                # Sort by sharpe ratio
                pairs.sort(key=lambda x: x["sharpe_ratio"], reverse=True)

                response = {
                    "status": "success",
                    "timeframe": timeframe,
                    "count": len(pairs),
                    "best_pair": pairs[0] if pairs else None,
                    "all_pairs": pairs,
                }

                # Clean response to remove NaN/Infinity values
                response = clean_response(response)

                if cache:
                    cache.set(cache_key, response)

                return jsonify(response)

            except Exception as e:
                logger.error(
                    f"Error in get_pair_comparison (timeframe={timeframe}): {type(e).__name__}: {e}"
                )
                import traceback

                logger.error(f"Traceback: {traceback.format_exc()}")
                return jsonify({"error": str(e), "type": type(e).__name__}), 500
            finally:
                if db:
                    db.close()

        @bp.route("/comparison/matrix/<int:timeframe>", methods=["GET"])
        def get_comparison_matrix(timeframe):
            """Get strategy vs pair performance matrix.

            Returns a matrix showing each strategy's performance on each pair.
            Useful for identifying optimal strategy-pair combinations.
            """
            cache_key = f"matrix_{timeframe}"
            if cache and cache.get(cache_key):
                return jsonify(cache.get(cache_key))

            db = None
            try:
                import json

                db = get_db_connection()
                cursor = db.conn.cursor()

                tf_str = f"M{timeframe}" if timeframe < 60 else f"H{timeframe//60}"
                logger.debug(f"Executing matrix query for timeframe: {tf_str}")

                # Get all strategy/pair combinations with raw metrics JSON
                query = """
                    SELECT 
                        tp.symbol,
                        bs.name as strategy,
                        b.metrics
                    FROM backtest_backtests b
                    JOIN backtest_strategies bs ON b.strategy_id = bs.id
                    JOIN tradable_pairs tp ON b.symbol_id = tp.id
                    WHERE b.timeframe = ? AND b.metrics IS NOT NULL
                    ORDER BY tp.symbol, bs.name
                """

                cursor.execute(query, (tf_str,))
                results = cursor.fetchall()
                logger.debug(
                    f"Matrix query returned {len(results)} rows for timeframe {tf_str}"
                )

                # Build matrix structure with Python JSON parsing
                matrix = {}
                for row in results:
                    symbol = row[0]
                    strategy = row[1]
                    metrics_json = row[2]

                    if symbol not in matrix:
                        matrix[symbol] = {}

                    try:
                        metrics = json.loads(metrics_json)
                        # Clean metrics to remove NaN/Infinity
                        metrics = clean_metrics(metrics)
                        matrix[symbol][strategy] = {
                            "sharpe_ratio": round(metrics.get("sharpe_ratio", 0), 3),
                            "return_pct": round(metrics.get("return", 0), 2),
                            "profit_factor": round(metrics.get("profit_factor", 0), 2),
                        }
                    except json.JSONDecodeError:
                        logger.warning(
                            f"Failed to parse metrics JSON for {symbol}/{strategy}"
                        )
                        continue

                response = {
                    "status": "success",
                    "timeframe": timeframe,
                    "matrix": matrix,
                }

                # Clean response to remove NaN/Infinity values
                response = clean_response(response)

                if cache:
                    cache.set(cache_key, response)

                return jsonify(response)

            except Exception as e:
                logger.error(
                    f"Error in get_comparison_matrix (timeframe={timeframe}): {type(e).__name__}: {e}"
                )
                import traceback

                logger.error(f"Traceback: {traceback.format_exc()}")
                return jsonify({"error": str(e), "type": type(e).__name__}), 500
            finally:
                if db:
                    db.close()

        @bp.route("/health", methods=["GET"])
        def health_check():
            """Health check endpoint."""
            try:
                db = get_db_connection()
                cursor = db.conn.cursor()
                cursor.execute("SELECT 1")
                cursor.fetchone()

                return jsonify(
                    {"status": "healthy", "timestamp": datetime.now().isoformat()}
                )

            except Exception as e:
                return jsonify({"status": "unhealthy", "error": str(e)}), 500

        return bp

    def register_routes(self, app):
        """Register blueprint routes with Flask app."""
        app.register_blueprint(self.blueprint)
        logger.info("Dashboard API routes registered")


class ReportCache:
    """Simple cache for report generation results."""

    def __init__(self, ttl_seconds: int = 300):
        """
        Initialize cache.

        Args:
            ttl_seconds: Time-to-live for cached entries
        """
        self.ttl_seconds = ttl_seconds
        self.cache = {}
        self.timestamps = {}

    def get(self, key: str) -> Optional[Dict]:
        """Get cached value if valid."""
        if key not in self.cache:
            return None

        # Check TTL
        age = (datetime.now() - self.timestamps[key]).total_seconds()
        if age > self.ttl_seconds:
            del self.cache[key]
            del self.timestamps[key]
            return None

        return self.cache[key]

    def set(self, key: str, value: Dict):
        """Cache a value."""
        self.cache[key] = value
        self.timestamps[key] = datetime.now()

    def clear(self, pattern: Optional[str] = None):
        """Clear cache (optionally by pattern)."""
        if pattern is None:
            self.cache.clear()
            self.timestamps.clear()
        else:
            keys_to_delete = [k for k in self.cache if pattern in k]
            for k in keys_to_delete:
                del self.cache[k]
                del self.timestamps[k]
